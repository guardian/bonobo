input {
    file {
        path => "/home/content-api/logs/bonobo.log"
        type => "application"
        codec => multiline {
            pattern => "^%{TIMESTAMP_ISO8601}"
            negate => true
            what => "previous"
        }
    }

    file {
        path => "/home/content-api/logs/audit.log"
        type => "audit"
        codec => multiline {
            pattern => "^%{TIMESTAMP_ISO8601}"
            negate => true
            what => "previous"
        }
    }
}

filter {
    mutate {
        add_field => {
            "app" => "bonobo"
            "stack" => "content-api"
            "stage" =>  "@@STAGE"
        }
    }

    if [type] == "application" {
        grok {
            match => {
                # Version of logstash used in the ubuntu-xenial-capi AMI has an incorrect pattern for Java class names:
                # (?:[a-zA-Z$_][a-zA-Z$_0-9]*\.)+[a-zA-Z$_][a-zA-Z$_0-9]*)
                # which manifests in Bonobo since some log entries have class name "application" (i.e. no ".")
                # The pattern is corrected in e.g. logstash version 7.10.1.
                # However, this isn't compatible with the logstash-output-kinesis plugin.
                # Resolution is to use a custom pattern copied from the corrected pattern for Java class name.
                "message" => "%{TIMESTAMP_ISO8601:timestamp}  %{LOGLEVEL:level}  (?<class_name>(?:[a-zA-Z$_][a-zA-Z$_0-9]*\.)*[a-zA-Z$_][a-zA-Z$_0-9]*) - %{GREEDYDATA:message}"
            }
            overwrite => [ "message" ]
        }
    }
    else if [type] == "audit" {
        grok {
            match => {
                "message" => "%{TIMESTAMP_ISO8601:timestamp} - %{GREEDYDATA:message}"
            }
            overwrite => [ "message" ]
        }
    }

    date {
        # Use event timestamp as the logstash timestamp of the event.
        match => [ "timestamp", "ISO8601" ]
        # And then remove the field to avoid duplicated fields and conflicts with the logstash timestamp.
        remove_field => [ "timestamp" ]
    }
}

output {
    kinesis {
        stream_name => "@@LOGGING_STREAM"
        randomized_partition_key => true
        region => "@@REGION"
        codec => json_lines

        # Configures metrics that are sent to CloudWatch.
        # Since we have never used CloudWatch to debug issues with the Kinesis plugin, disable it for now to save costs.
        # If we consider re-enabling it in the future, we should configure the namespace per application,
        # to avoid the default namespace (KinesisProducerLibrary) making it hard to determine
        # to which logstash daemon (Pubflow, Concierge etc) the CloudWatch metrics apply.
        metrics_level => "none"
    }
}
